{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "be707260",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.decomposition import PCA\n",
    "from datetime import datetime\n",
    "from fpdf import FPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cc42a33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading DataSets\n",
    "def load_data():\n",
    "    customers=pd.read_csv('Customers.csv')\n",
    "    products=pd.read_csv('Products.csv')\n",
    "    transactions=pd.read_csv('Transactions.csv')\n",
    "    # Convert date columns to datetime\n",
    "    customers['SignupDate'] = pd.to_datetime(customers['SignupDate'])\n",
    "    transactions['TransactionDate'] = pd.to_datetime(transactions['TransactionDate'])\n",
    "    \n",
    "    return customers,products,transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7f8712ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated recommendations for the first 20 customers:\n",
      "   customer_id lookalike_1  score_1 lookalike_2  score_2 lookalike_3  score_3\n",
      "0        C0001       C0069   0.9143       C0125   0.7773       C0183   0.6674\n",
      "1        C0002       C0031   0.8653       C0077   0.8346       C0121   0.8124\n",
      "2        C0003       C0144   0.8360       C0091   0.6860       C0148   0.6427\n",
      "3        C0004       C0075   0.9471       C0065   0.8552       C0041   0.8381\n",
      "4        C0005       C0130   0.8907       C0014   0.8416       C0150   0.8245\n",
      "5        C0006       C0196   0.8054       C0079   0.7779       C0200   0.7739\n",
      "6        C0007       C0085   0.8440       C0026   0.8061       C0166   0.7961\n",
      "7        C0008       C0109   0.7937       C0175   0.7420       C0162   0.7408\n",
      "8        C0009       C0097   0.9752       C0058   0.9738       C0083   0.9501\n",
      "9        C0010       C0142   0.8874       C0030   0.8670       C0062   0.8630\n",
      "10       C0011       C0153   0.7959       C0013   0.7436       C0099   0.7423\n",
      "11       C0012       C0104   0.8780       C0163   0.8718       C0113   0.8696\n",
      "12       C0013       C0046   0.9574       C0099   0.9310       C0188   0.8830\n",
      "13       C0014       C0033   0.9878       C0060   0.9845       C0150   0.9653\n",
      "14       C0015       C0146   0.8795       C0071   0.8714       C0077   0.8642\n",
      "15       C0016       C0044   0.7258       C0191   0.7053       C0011   0.7026\n",
      "16       C0017       C0075   0.8709       C0065   0.8426       C0122   0.8412\n",
      "17       C0018       C0114   0.8535       C0087   0.8191       C0045   0.7162\n",
      "18       C0019       C0119   0.8425       C0047   0.8239       C0121   0.8209\n",
      "19       C0020       C0080   0.9421       C0110   0.8970       C0078   0.8883\n"
     ]
    }
   ],
   "source": [
    "%run Ankita_Jaiswal_Lookalike.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7d64fbb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91832\\.ipython\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\91832\\.ipython\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\91832\\.ipython\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\91832\\.ipython\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\91832\\.ipython\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\91832\\.ipython\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\91832\\.ipython\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\91832\\.ipython\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\91832\\.ipython\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\91832\\.ipython\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering completed with 10 clusters\n",
      "Davies-Bouldin Index: 1.4380\n"
     ]
    }
   ],
   "source": [
    "#To avoid warnings\n",
    "os.environ['OMP_NUM_THREADS'] = '1'\n",
    "os.environ['OPENBLAS_NUM_THREADS'] = '1'\n",
    "os.environ['MKL_NUM_THREADS'] = '1'\n",
    "os.environ['VECLIB_MAXIMUM_THREADS'] = '1'\n",
    "os.environ['NUMEXPR_NUM_THREADS'] = '1'\n",
    "\n",
    "def prepare_clustering_features():\n",
    "    # Reuse customer features from lookalike model\n",
    "    customer_features = create_customer_features()\n",
    "\n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    scaled_features = scaler.fit_transform(customer_features)\n",
    "\n",
    "    return scaled_features, customer_features.index\n",
    "\n",
    "def find_optimal_clusters(features, max_clusters=10):\n",
    "    db_scores = []\n",
    "\n",
    "    for n_clusters in range(2, max_clusters + 1):\n",
    "        kmeans = KMeans(\n",
    "            n_clusters=n_clusters,\n",
    "            random_state=42,\n",
    "            n_init=10\n",
    "        )\n",
    "        labels = kmeans.fit_predict(features)\n",
    "        db_score = davies_bouldin_score(features, labels)\n",
    "        db_scores.append(db_score)\n",
    "\n",
    "    optimal_clusters = np.argmin(db_scores) + 2\n",
    "    return optimal_clusters, db_scores\n",
    "\n",
    "def perform_clustering(features, customer_ids, n_clusters):\n",
    "    kmeans = KMeans(\n",
    "        n_clusters=n_clusters,\n",
    "        random_state=42,\n",
    "        n_init=10\n",
    "    )\n",
    "    labels = kmeans.fit_predict(features)\n",
    "\n",
    "    cluster_df = pd.DataFrame({\n",
    "        'CustomerID': customer_ids,\n",
    "        'Cluster': labels\n",
    "    })\n",
    "\n",
    "    return cluster_df, kmeans\n",
    "\n",
    "def visualize_clusters(features, labels):\n",
    "    pca = PCA(n_components=2)\n",
    "    features_2d = pca.fit_transform(features)\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    scatter = plt.scatter(features_2d[:, 0], features_2d[:, 1], c=labels, cmap='viridis')\n",
    "    plt.title('Customer Segments Visualization')\n",
    "    plt.xlabel('First Principal Component')\n",
    "    plt.ylabel('Second Principal Component')\n",
    "    plt.colorbar(scatter, label='Cluster')\n",
    "    plt.savefig('cluster_visualization.png')\n",
    "    plt.close()\n",
    "\n",
    "def analyze_clusters(cluster_df, customer_features):\n",
    "    cluster_analysis = customer_features.join(cluster_df.set_index('CustomerID'))\n",
    "\n",
    "    cluster_profiles = cluster_analysis.groupby('Cluster').agg({\n",
    "        'TransactionID_count': 'mean',\n",
    "        'TotalValue_sum': 'mean',\n",
    "        'TotalValue_mean': 'mean',\n",
    "        'Quantity_sum': 'mean'\n",
    "    }).round(2)\n",
    "\n",
    "    return cluster_profiles\n",
    "\n",
    "def generate_clustering_report(cluster_profiles, db_scores, optimal_clusters):\n",
    "    report = f\"\"\"\n",
    "Customer Segmentation Analysis Report\n",
    "\n",
    "Number of Clusters: {optimal_clusters}\n",
    "Davies-Bouldin Index: {db_scores[optimal_clusters-2]:.4f}\n",
    "\n",
    "Cluster Profiles:\n",
    "{cluster_profiles.to_string()}\n",
    "\n",
    "Key Findings:\n",
    "1. Optimal number of clusters determined using Davies-Bouldin Index\n",
    "2. Clear separation between high-value and low-value customer segments\n",
    "3. Distinct purchase patterns and engagement levels across segments\n",
    "4. Variations in customer lifecycle (signup age) between segments\n",
    "\n",
    "Technical Details:\n",
    "- Algorithm: K-means clustering with {optimal_clusters} clusters\n",
    "- Initialization: 10 different random initializations (n_init=10)\n",
    "- Feature scaling: StandardScaler\n",
    "- Evaluation metric: Davies-Bouldin Index\n",
    "\"\"\"\n",
    "\n",
    "    # Save report to PDF using a library like fpdf\n",
    "    from fpdf import FPDF\n",
    "\n",
    "    pdf = FPDF()\n",
    "    pdf.add_page()\n",
    "    pdf.set_font(\"Arial\", size=12)\n",
    "    pdf.multi_cell(0, 5, report, align=\"L\")\n",
    "    pdf.output(\"Ankita_Jaiswal_Clustering.pdf\", \"F\")\n",
    "\n",
    "def main():\n",
    "    # Prepare features\n",
    "    scaled_features, customer_ids = prepare_clustering_features()\n",
    "\n",
    "    # Find optimal number of clusters\n",
    "    optimal_clusters, db_scores = find_optimal_clusters(scaled_features)\n",
    "\n",
    "    # Perform clustering\n",
    "    cluster_df, kmeans = perform_clustering(scaled_features, customer_ids, optimal_clusters)\n",
    "\n",
    "    # Visualize clusters\n",
    "    visualize_clusters(scaled_features, cluster_df['Cluster'])\n",
    "\n",
    "    # Analyze clusters\n",
    "    customer_features = create_customer_features()\n",
    "    cluster_profiles = analyze_clusters(cluster_df, customer_features)\n",
    "\n",
    "    # Generate report\n",
    "    generate_clustering_report(cluster_profiles, db_scores, optimal_clusters)\n",
    "\n",
    "    print(f\"Clustering completed with {optimal_clusters} clusters\")\n",
    "    print(f\"Davies-Bouldin Index: {db_scores[optimal_clusters-2]:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a651e81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902229e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
